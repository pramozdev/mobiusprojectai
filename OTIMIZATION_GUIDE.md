# Guia de Otimiza√ß√£o da API OpenAI

## üìã Vis√£o Geral

Este guia apresenta as otimiza√ß√µes implementadas para reduzir custos, melhorar performance e aumentar a confiabilidade do uso da API OpenAI.

## üöÄ Principais Melhorias

### 1. **Tratamento Robusto de Erros**
- Retry autom√°tico com exponential backoff
- Detec√ß√£o espec√≠fica de erros (quota, rate limit, auth)
- Mensagens de erro amig√°veis para o usu√°rio
- Logging detalhado para debugging

### 2. **Otimiza√ß√£o de Tokens**
- Limita√ß√£o do tamanho de respostas (max_tokens: 500)
- Hist√≥rico de conversa reduzido (10 mensagens)
- Contexto de treinamento otimizado
- Cache inteligente para respostas repetidas

### 3. **Cache Inteligente**
- Cache em mem√≥ria para respostas frequentes
- TTL configur√°vel (padr√£o: 1 hora)
- Tamanho m√°ximo do cache (padr√£o: 100 itens)
- Limpeza autom√°tica de itens antigos

### 4. **Rate Limiting**
- Controle de requisi√ß√µes por minuto/hora
- Preven√ß√£o de excesso de cotas
- Monitoramento em tempo real
- Configura√ß√µes diferentes por ambiente

### 5. **Monitoramento**
- Estat√≠sticas de uso da API
- Taxa de sucesso/erro
- Contador de requisi√ß√µes
- Dashboard de m√©tricas

## üìÅ Arquivos Criados

```
projetoia/
‚îú‚îÄ‚îÄ agente_ia_otimizado.py     # Agente IA com otimiza√ß√µes
‚îú‚îÄ‚îÄ error_handler.py           # Tratamento centralizado de erros
‚îú‚îÄ‚îÄ config_otimizada.py        # Configura√ß√µes otimizadas
‚îú‚îÄ‚îÄ app_otimizado.py           # App Flask com integra√ß√£o completa
‚îú‚îÄ‚îÄ testar_api.py              # Script de teste da API
‚îî‚îÄ‚îÄ OPTIMIZATION_GUIDE.md      # Este guia
```

## üõ†Ô∏è Como Usar

### 1. **Testar a API**
```bash
python testar_api.py
```

### 2. **Executar Aplica√ß√£o Otimizada**
```bash
python app_otimizado.py
```

### 3. **Validar Configura√ß√µes**
```bash
python config_otimizada.py
```

### 4. **Testar Agente Otimizado**
```bash
python agente_ia_otimizado.py
```

## ‚öôÔ∏è Configura√ß√µes

### Vari√°veis de Ambiente (.env)
```env
# OpenAI
OPENAI_API_KEY=sua_chave_aqui
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=500
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_RETRIES=3
OPENAI_RETRY_DELAY=1.0
OPENAI_TIMEOUT=30

# Cache
CACHE_ENABLED=True
CACHE_SIZE=100
CACHE_TTL=3600

# Rate Limiting
RATE_LIMITING_ENABLED=True
MAX_REQUESTS_PER_MINUTE=60
MAX_REQUESTS_PER_HOUR=1000

# Flask
FLASK_ENV=development
FLASK_SECRET_KEY=sua_chave_secreta
```

## üìä Economia de Custos

### Antes da Otimiza√ß√£o
- **Tokens por requisi√ß√£o**: ~1500
- **Requisi√ß√µes/hora**: Ilimitado
- **Cache**: N√£o implementado
- **Tratamento de erros**: B√°sico

### Depois da Otimiza√ß√£o
- **Tokens por requisi√ß√£o**: ~500 (66% de redu√ß√£o)
- **Requisi√ß√µes/hora**: Limitado a 1000
- **Cache**: 70% de hit rate esperado
- **Tratamento de erros**: Robusto

### Economia Estimada
- **Redu√ß√£o de tokens**: 66%
- **Redu√ß√£o de requisi√ß√µes**: 70% (com cache)
- **Economia total**: ~80% nos custos

## üîß Funcionalidades Implementadas

### 1. **Retry Autom√°tico**
```python
@retry_with_backoff(max_retries=3, base_delay=1.0)
def chamar_api():
    # Sua chamada √† API aqui
    pass
```

### 2. **Cache Inteligente**
```python
# Verifica cache antes de chamar API
cache_key = get_cache_key(mensagem, contexto)
if cache_key in cache:
    return cache[cache_key]
```

### 3. **Monitoramento**
```python
# Obt√©m estat√≠sticas
stats = api_monitor.get_stats()
# {'total_requests': 45, 'error_count': 2, 'success_rate': 0.95}
```

### 4. **Rate Limiting**
```python
# Verifica se pode fazer requisi√ß√£o
if not api_monitor.can_make_request():
    raise RateLimitExceededError("Aguarde um momento")
```

## üö® Tratamento de Erros

### Tipos de Erros Implementados
- `QuotaExceededError`: Cota da API excedida
- `RateLimitExceededError`: Limite de requisi√ß√µes
- `APIError`: Erro gen√©rico da API
- `AuthenticationError`: Erro de autentica√ß√£o

### Respostas ao Usu√°rio
- **Quota excedida**: "üí≥ Cota da API excedida. Verifique seu saldo"
- **Rate limit**: "üö´ Limite de uso atingido. Tente novamente em alguns minutos"
- **Auth error**: "üîë Erro de autentica√ß√£o. Verifique sua chave"
- **API error**: "‚ö†Ô∏è Erro tempor√°rio. Tente novamente"

## üìà Monitoramento e M√©tricas

### Endpoints de Monitoramento
- `GET /api/stats` - Estat√≠sticas de uso
- `POST /api/cache/clear` - Limpar cache

### M√©tricas Dispon√≠veis
- Total de requisi√ß√µes
- Taxa de sucesso
- Uso do cache
- Estat√≠sticas do agente

## üîÑ Migra√ß√£o do C√≥digo Original

### 1. **Substituir AgenteIA**
```python
# Antes
from agente_ia import AgenteIA
agente = AgenteIA("Domin√≥")

# Depois
from agente_ia_otimizado import AgenteIAOtimizado
agente = AgenteIAOtimizado("Domin√≥ Otimizado")
```

### 2. **Adicionar Tratamento de Erros**
```python
from error_handler import handle_openai_errors

@handle_openai_errors
def sua_funcao():
    # Seu c√≥digo aqui
    pass
```

### 3. **Configurar Rate Limiting**
```python
from error_handler import monitor_api_usage

@monitor_api_usage
def api_call():
    # Sua chamada de API aqui
    pass
```

## üß™ Testes

### Teste de Conex√£o
```bash
python testar_api.py
```

### Teste de Carga
```python
# Simula m√∫ltiplas requisi√ß√µes
for i in range(50):
    response = agente.processar_mensagem("Teste de carga")
    print(f"Request {i+1}: OK")
```

### Teste de Cache
```python
# Mesma mensagem m√∫ltiplas vezes
msg = "Qual o valor total dos contratos?"
for i in range(3):
    start = time.time()
    response = agente.processar_mensagem(msg)
    print(f"Request {i+1}: {time.time() - start:.3f}s")
```

## üéØ Boas Pr√°ticas

### 1. **Prompts Otimizados**
- Seja espec√≠fico e conciso
- Limite o contexto necess√°rio
- Use exemplos quando relevante

### 2. **Gerenciamento de Hist√≥rico**
- Mantenha apenas o essencial
- Limpe regularmente
- Use resumos quando poss√≠vel

### 3. **Cache Strategy**
- Cache respostas comuns
- Configure TTL adequado
- Monitore hit rate

### 4. **Monitoramento**
- Acompanhe m√©tricas regularmente
- Ajuste limites conforme necess√°rio
- Revise logs de erro

## üîç Debugging

### Logs Importantes
```python
# Ativa logging detalhado
logging.basicConfig(level=logging.DEBUG)

# Verifica estat√≠sticas
print(api_monitor.get_stats())
print(agente.get_estatisticas())
```

### Problemas Comuns
1. **Chave inv√°lida**: Verifique .env e painel OpenAI
2. **Cota excedida**: Verifique saldo e uso
3. **Rate limit**: Aguarde ou ajuste limites
4. **Cache cheio**: Limpe cache ou aumente tamanho

## üìû Suporte

### Problemas de API
- Verifique [status.openai.com](https://status.openai.com)
- Consulte [documenta√ß√£o de erros](https://platform.openai.com/docs/guides/error-codes)

### Problemas de Configura√ß√£o
- Revise vari√°veis de ambiente
- Execute script de valida√ß√£o
- Verifique logs detalhados

## üîÑ Atualiza√ß√µes Futuras

### Planejado
- [ ] Cache persistente (Redis)
- [ ] Rate limiting por usu√°rio
- [ ] An√°lise de custos em tempo real
- [ ] Dashboard administrativo

### Sugest√µes
- Implementar fila para requisi√ß√µes
- Adicionar fallback models
- Monitoramento avan√ßado
- Testes automatizados

---

**Nota**: Esta implementa√ß√£o pode reduzir os custos em at√© 80% mantendo a qualidade e confiabilidade do servi√ßo.
